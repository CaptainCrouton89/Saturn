# ============================================================================
# OpenTelemetry & Tracing Configuration
# ============================================================================

# Tracing mode: 'console' | 'langfuse' | 'disabled'
# - console: Logs traces to stdout (default in development, no setup needed)
# - langfuse: Exports to self-hosted or cloud Langfuse instance
# - disabled: No tracing (default in production)
TRACING_MODE=langfuse

# Langfuse Configuration (only needed if TRACING_MODE=langfuse)
# Get API keys from self-hosted Langfuse instance or https://langfuse.com

# Langfuse Public API Key
LANGFUSE_PUBLIC_KEY=pk-lf-3d077f18-c826-4d6e-a1ba-f896eccdad5f

# Langfuse Secret API Key
LANGFUSE_SECRET_KEY=sk-lf-4e1e27e2-f290-42f4-acd3-0d6c8f2ea98c

# Langfuse Instance URL
# For self-hosted: http://localhost:3000
# For cloud: https://us.cloud.langfuse.com
LANGFUSE_BASEURL=https://us.cloud.langfuse.com

# ============================================================================
# Database Configuration
# ============================================================================

# Neo4j (Knowledge Graph)
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password

# PostgreSQL / Supabase (Transcripts & Embeddings)
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_ANON_KEY=xxx
SUPABASE_SERVICE_ROLE_KEY=xxx

# ============================================================================
# LLM Configuration
# ============================================================================

# OpenAI API Key
OPENAI_API_KEY=sk-xxx

# ============================================================================
# Server Configuration
# ============================================================================

PORT=3001
NODE_ENV=development
