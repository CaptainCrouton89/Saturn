---
project_name: Cosmo
tagline: "An AI companion that asks you questions, not the other way around"
summary: |
  Cosmo is a proactive AI companion app that conducts engaging conversations by asking thoughtful questions rather than waiting for user prompts. It combines the conversational depth of therapy, the insight partnership of a smart friend, and productivity tools that turn thinking into artifacts—all with near-zero friction.

primary_goal: |
  Build an iOS-first, voice-first conversational AI that engages users through Socratic questioning and remembers everything you tell it. Replace doom-scrolling with meaningful conversations by making it effortless to talk through whatever is on your mind.

  Critical principle: No modes, no topic suggestions, no friction. User opens app → speaks → Cosmo asks good questions informed by past context.

success_metrics:
  engagement:
    - Daily active usage rate
    - Average conversation length (target: 10-20 minutes)
    - Repeat usage frequency (return within 24 hours)
  value_delivery:
    - User-reported insights gained through conversation
    - Quality of questions asked (engaging without being annoying)
    - Effective use of past context to make conversations relevant
  product_market_fit:
    - Users describe experience as "talking to a friend"
    - Users choose Cosmo over social media scrolling (bedtime use case)
    - Increased social engagement and thoughtfulness post-session
    - Organic conversation flow without friction

target_users:
  primary:
    - Solo founders and remote workers spending significant time alone thinking
    - People in life transitions (relocations, career changes, breakups)
    - Introverts who think by talking but lack conversational outlets
  secondary:
    - Anyone without roommates/partners for daily processing
    - People interested in self-knowledge but find journaling tedious
    - Creative professionals needing verbal ideation

core_features:
  - id: F-01
    name: "Minimal Onboarding"
    description: "Quick setup collecting name + 1-2 open questions, then immediate transition to first conversation. No tutorial, no mode selection."
    priority: P0
    acceptance_criteria:
      - Onboarding completes in ~2 minutes
      - Collects: name, 1-2 open questions (interests, what's on mind)
      - No tutorial screens or feature tours
      - Seamless transition to first conversation
      - User can skip optional questions

  - id: F-02
    name: "Blank Slate Conversation Start"
    description: "User opens app → microphone ready → user speaks first. No topic suggestions, no conversation starters. Zero friction."
    priority: P0
    acceptance_criteria:
      - App opens with mic ready (no prompts)
      - User speaks first about whatever is on their mind
      - No greeting from Cosmo, no topic menu
      - Works for both first-time and returning users
      - No delay or friction to start talking

  - id: F-03
    name: "Context-Aware Background Loading"
    description: "Before Cosmo's first response, system loads relevant past context (recent summary + semantic search + active entities from graph) to inform conversation without overwhelming"
    priority: P0
    acceptance_criteria:
      - Loads recent summary (last 1-2 conversations)
      - Semantic search for relevant past snippets if topic aligns
      - Active entities from Neo4j (people, projects, topics mentioned in last 14 days)
      - Context loading invisible to user (background)
      - Total context budget ~2-3K tokens

  - id: F-04
    name: "Adaptive Socratic Questioning"
    description: "Cosmo conducts natural conversation using primarily Socratic questioning to lead users to insights. Memory used for understanding, NOT explicit recall/showmanship."
    priority: P0
    acceptance_criteria:
      - Questions feel natural and authentic (not robotic)
      - Recognizes when to probe deeper vs. move on
      - Uses past context for understanding (not 'I remember when...')
      - High temperature responses with natural speech patterns
      - Turn-based interaction (clear back-and-forth)

  - id: F-05
    name: "Sliding Window Context Management"
    description: "During conversation, maintain sliding window of last N turns (10-15 exchanges) to handle long conversations without hitting token limits"
    priority: P0
    acceptance_criteria:
      - Last 10-15 turns kept verbatim in context
      - Older turns summarized or dropped
      - Conversation can last 20+ minutes without degradation
      - Total context budget ~50K tokens (conversation + pre-loaded context)

  - id: F-06
    name: "Auto-End on Timeout"
    description: "Conversation automatically ends after 3-5 minutes of silence. No manual 'end conversation' button required."
    priority: P0
    acceptance_criteria:
      - Detects user silence for 3-5 minutes
      - Auto-ends and saves conversation
      - User can reopen app anytime for new conversation
      - No confirmation prompt needed

  - id: F-07
    name: "Conversation Memory & Storage"
    description: "All conversations stored in PostgreSQL with full transcript, embeddings for semantic search. Privacy-secure encrypted storage."
    priority: P0
    acceptance_criteria:
      - Full transcript saved as JSON
      - Embeddings generated for semantic search
      - All conversations searchable
      - Privacy-secure storage (encrypted)
      - User can access past conversations

  - id: F-08
    name: "Batch Entity Extraction & Graph Updates"
    description: "After conversation ends, batch process to extract entities (people, projects, topics, ideas) and update Neo4j knowledge graph with provenance tracking"
    priority: P0
    acceptance_criteria:
      - Entity extraction runs after conversation (async)
      - Creates/updates Person, Project, Topic, Idea nodes in Neo4j
      - Entity resolution via alias tracking and confidence scores
      - Updates entity properties (current_life_situation, blockers, etc.)
      - Records provenance (conversation_id as last_update_source)
      - Process completes in 30-120 seconds

  - id: F-09
    name: "Transcript Synthesis (Rare)"
    description: "Agent can synthesize transcript into artifacts (blog posts, plans, notes) when genuinely valuable. Not prompted after every conversation - agent-initiated only."
    priority: P0
    acceptance_criteria:
      - Agent detects when conversation was productive
      - Offers synthesis only when truly valuable (rare)
      - Generates blog posts, plans, notes from transcripts
      - Output is draft-quality (copy-to-clipboard)
      - No artifact storage in app (simple copy/paste)

  - id: F-10
    name: "Voice-First Interaction with Real-Time Transcript"
    description: "Natural speech-to-text input and text-to-speech output with live caption-style transcript showing both user speech and Cosmo's responses"
    priority: P0
    acceptance_criteria:
      - Real-time speech recognition (STT)
      - Natural voice synthesis (TTS)
      - Live transcript showing user words + Cosmo's responses as text
      - User can read while also hearing (dual modality)
      - Handles background noise reasonably
      - Turn-based interaction (no interruption handling in MVP)

  - id: F-11
    name: "Agent Tool Access"
    description: "Cosmo has access to tools during conversation: memory retrieval (search past conversations), web search (factual lookup), and synthesis (create artifacts)"
    priority: P0
    acceptance_criteria:
      - Memory retrieval tool for searching specific past context
      - Web search tool for current events or factual questions
      - Synthesis tool for creating artifacts from transcript
      - Tools used sparingly (only when genuinely helpful)
      - Memory retrieval happens mostly via pre-loaded context

features_not_in_mvp:
  - Smart conversation opening / topic suggestions ("Conversation DJ")
  - Mode selection (therapy/brainstorm/entertainment modes)
  - Question preference learning (multi-armed bandit approach)
  - Proactive pattern recognition ("You've mentioned this 3 times")
  - Error learning (tracking bad questions)
  - Artifact storage/library (synthesis outputs simple copy-to-clipboard)
  - Calendar/email integration
  - All-day ambient transcription
  - Proactive notifications (only user-triggered)
  - External news/event sourcing
  - Integration with third-party services
  - Cloud sync across devices (iPhone-only for MVP)
  - Archive timeline/insights dashboard

technical_architecture:
  data_storage:
    postgresql:
      purpose: "Time-series conversation storage and full content"
      stores:
        - Complete conversation transcripts (JSON format)
        - Vector embeddings for semantic search across all conversations
        - Basic user preferences (loaded into system prompt)
      queries:
        - Semantic search for relevant past conversation snippets
        - Full-text search across all conversations
        - Conversation retrieval by date/topic

    neo4j:
      purpose: "Structured knowledge graph for entity relationships"
      stores:
        - "Entities: Person, Project, Topic, Idea nodes with rich context properties"
        - "Relationships: who's involved in what, which topics relate, what blocks what"
        - Current state only (no historical tracking - keeps graph fast)
        - Embeddings on entities for semantic similarity
        - Alias tracking for entity resolution (confidence scores, canonical names)
      queries:
        - Active entities (mentioned in last 14 days)
        - Entity resolution (matching mentions to existing nodes)
        - Relationship traversal (finding connected entities)
        - Semantic similarity (finding related projects/ideas/topics)

  processing_flow:
    conversation_start:
      - "Load recent summary (last 1-2 conversations from PostgreSQL)"
      - "Semantic search for relevant past snippets (PostgreSQL embeddings)"
      - "Query Neo4j for active entities (people, projects, topics mentioned in last 14 days)"
      - "Load user preferences from PostgreSQL"
      - "Assemble system prompt with all context (~2-3K tokens)"

    during_conversation:
      - "Turn-based: User speaks → STT → LLM processes → response → TTS"
      - "Sliding window: Last 10-15 turns kept verbatim, older turns summarized/dropped"
      - "Total context budget: ~50K tokens (conversation + pre-loaded context)"
      - "Agent tools available: memory retrieval, web search, synthesis (used sparingly)"

    conversation_end:
      - "Save full transcript to PostgreSQL (JSON)"
      - "Batch entity extraction (async background job, 30-120 seconds)"
      - "Entity resolution: Match to existing Neo4j nodes or create new ones"
      - "Update Neo4j: Entity properties, relationships, provenance tracking"
      - "Generate embeddings: Conversation summary + transcript snippets"
      - "Save embeddings to PostgreSQL for future semantic search"

  entity_extraction:
    approach: "Batch processing after conversation ends (not real-time)"
    entities:
      - "Person: name, relationship_type, current_life_situation, etc."
      - "Project: name, status, vision, blockers, confidence_level, etc."
      - "Topic: name, description, category"
      - "Idea: summary, status, evolution_notes, obstacles, next_steps, etc."
    resolution:
      - "Canonical name matching + alias lookup"
      - "Confidence scoring (0-1 scale)"
      - "Provenance tracking (conversation_id as last_update_source)"
      - "Bounded arrays (max 8-15 items per property to prevent bloat)"

  context_management:
    pre_loaded_context:
      - "Recent conversations: Summaries only (~500 tokens)"
      - "Active entities: Current properties from Neo4j (~1-2K tokens)"
      - "Semantic matches: Top 3-5 relevant snippets if topic aligns (~500 tokens)"
      - "User preferences: Question styles to avoid, topics (~200 tokens)"

    sliding_window:
      - "Last 10-15 turns: Verbatim in context"
      - "Older turns: Summarized (2-3 sentences) or dropped"
      - "Allows conversations of 20+ minutes without token limit issues"

future_stages:
  stage_2_proactive_intelligence:
    - Question preference learning (multi-armed bandit approach)
    - Error learning (track when questions land poorly)
    - Smart notification timing based on user patterns
    - Pattern recognition surfacing ("You've been coming back to X a lot")
    - Event awareness and deadline prep
    - Enhanced web search and research capabilities

  stage_3_life_integration:
    - Calendar integration
    - Email context awareness
    - Multi-modal input (images, documents)
    - Conversation topic sourcing from external events/news
    - Cloud sync across devices (iPhone, iPad, web)
    - Archive timeline and insights dashboard

  stage_4_ambient_companion:
    - Background transcription (with explicit permission)
    - Proactive re-engagement on dormant topics
    - Life archive with advanced pattern analysis
    - Long-term contradiction detection (values vs. behavior)

key_design_principles:
  - Conversational, not transactional (not task-focused like Siri)
  - Questions over answers (Socratic method)
  - No generic advice (deep exploration beats platitudes)
  - Authentic voice (high temperature, natural speech patterns)
  - Memory for understanding, not showmanship (context informs questions, not "I remember when...")
  - Reads the room (knows when to probe vs. move on)
  - Effortless engagement (near-zero friction - open app and speak)
  - No modes or settings (one adaptive conversational system)
  - Batch processing over real-time complexity (entity extraction happens after conversation)

open_questions:
  - How to avoid "creepy companion" perception while being proactive?
  - Privacy model for therapy-level conversations?
  - Business model (subscription/per-conversation/freemium)?
  - Maintaining conversation quality at scale?
  - When does memory become overwhelming vs. beneficial?
