/**
 * Evaluator Agent - AI SDK agent for querying knowledge graph
 *
 * Uses explore and traverse tools to answer questions about ingested dialogues.
 */

import { generateText } from 'ai';
import { createOpenAI } from '@ai-sdk/openai';
import type { MessageParam } from 'ai';
import { createExploreTool } from '../../src/agents/tools/retrieval/explore.tool.js';
import { createTraverseTool } from '../../src/agents/tools/retrieval/traverse.tool.js';
import type { ExploreOutput, TraverseOutput } from './types.js';
import { withAgentTracing } from '../../src/utils/tracing.js';

/**
 * System prompt for evaluator agent
 */
const EVALUATOR_SYSTEM_PROMPT = `You are an expert knowledge graph query assistant. Your role is to answer questions by exploring and traversing a user's knowledge graph.

**Available Tools:**
1. **explore**: Semantic search across the knowledge graph. Use this first to find relevant entities, concepts, people, and sources.
2. **traverse**: Execute custom Cypher queries for specific navigation. Use after explore for detailed information.

**Your Process:**
1. Analyze the question to understand what information is needed
2. Use explore tool with semantic queries to find relevant nodes
3. If more specific details needed, use traverse tool with targeted Cypher queries
4. Synthesize the retrieved information into a clear, concise answer
5. If information is not found in the graph, clearly state "Information not found"

**Important:**
- Always use explore first for broad discovery
- Use traverse for specific details (e.g., all relationships of a node, temporal queries)
- Keep answers factual and grounded in the retrieved data
- Cite entity_keys when referencing specific nodes
- If uncertain, acknowledge limitations

Answer the user's question based on the knowledge graph.`;

/**
 * Run the evaluator agent for a single query
 *
 * @param userId - User ID for graph scoping
 * @param query - Question to answer
 * @returns Answer string and full message history
 */
async function runEvaluatorAgentImpl(
  userId: string,
  query: string
): Promise<{ answer: string; messages: MessageParam[] }> {
  // Create tools bound to user_id
  const exploreTool = createExploreTool(userId);
  const traverseTool = createTraverseTool(userId);
  const tools = {
    explore: exploreTool,
    traverse: traverseTool,
  };

  // Create AI SDK model
  const openai = createOpenAI({ apiKey: process.env.OPENAI_API_KEY });

  // Build messages array
  const messages: MessageParam[] = [
    { role: 'system', content: EVALUATOR_SYSTEM_PROMPT },
    { role: 'user', content: query },
  ];

  // Run generateText with tools and multi-step execution
  const result = await generateText({
    model: openai('gpt-4.1-mini'),
    messages,
    tools,
    maxSteps: 10,
  });

  // Extract answer from final text
  const answer = result.text;

  if (!answer) {
    throw new Error('No answer content generated by model');
  }

  // Build message history: include input messages and final answer
  // For evaluation purposes, this provides the conversation context
  const messageHistory: MessageParam[] = [
    ...messages,
    { role: 'assistant', content: answer },
  ];

  return {
    answer,
    messages: messageHistory,
  };
}

/**
 * Exported wrapped version with LangSmith tracing
 */
export const runEvaluatorAgent = withAgentTracing(
  runEvaluatorAgentImpl as (...args: unknown[]) => unknown,
  'evaluator',
  { phase: 'retrieval' }
) as unknown as typeof runEvaluatorAgentImpl;

/**
 * Batch evaluate multiple queries for a dialogue
 *
 * @param userId - User ID for graph scoping
 * @param queries - Array of questions to answer
 * @returns Array of answers with timing information
 */
export async function batchEvaluate(
  userId: string,
  queries: string[]
): Promise<Array<{ query: string; answer: string; latency_ms: number }>> {
  const results = [];

  for (const query of queries) {
    const startTime = Date.now();

    try {
      const { answer } = await runEvaluatorAgent(userId, query);
      const latency_ms = Date.now() - startTime;

      results.push({ query, answer, latency_ms });
    } catch (error) {
      const latency_ms = Date.now() - startTime;
      results.push({
        query,
        answer: `Error: ${error instanceof Error ? error.message : 'Unknown error'}`,
        latency_ms,
      });
    }
  }

  return results;
}
